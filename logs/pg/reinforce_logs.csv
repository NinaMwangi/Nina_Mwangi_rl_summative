learning_rate,gamma,hidden_dim,max_grad_norm,reward_normalization,success_threshold,log_interval,eval_episodes,env_name,final_mean_reward,total_episodes,final_loss,timestamp
0.01,0.99,128,1.0,True,7,50,10,AngazaEnv,0.05799999999999997,500,0.03430986404418945,2025-07-30T22:05:08.540351
0.001,0.99,128,1.0,True,7,50,10,AngazaEnv,-1.7142857142857133,500,-0.016692208126187325,2025-07-30T22:46:40.589141
0.001,0.99,128,1.0,True,7,50,30,AngazaEnv,-2.3479999999999994,500,-0.008830392733216286,2025-07-30T22:52:36.739508
0.001,0.99,128,1.0,True,7,50,30,AngazaEnv,-2.322,750,-0.0016471280250698328,2025-07-30T22:57:00.692303
0.0005,0.99,128,1.0,True,7,50,30,AngazaEnv,-0.6299999999999997,1000,-0.0017886064015328884,2025-07-30T23:00:32.856009
0.0005,0.99,128,1.0,True,7,50,50,AngazaEnv,-1.0658141036401502e-16,1500,0.8175883889198303,2025-07-30T23:07:12.048053
